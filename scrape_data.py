#!/usr/bin/env python3
import json
import requests
import os
from datetime import datetime

def scrape_artificialanalysis():
    print("ğŸ“Š Artificial Analysis APIì—ì„œ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ë° ë§¤í•‘ ì¤‘...")
    
    api_key = aa_nlHXrHmYGAApxkFnjBrBFcYPegOsmqKZ
    if not api_key:
        print("âŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    # API v2 ì—”ë“œí¬ì¸íŠ¸
    url = "https://artificialanalysis.ai/api/v2/data/llms/models" 
    headers = {"x-api-key": api_key, "Content-Type": "application/json"}
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code == 200:
            api_data = response.json()
            # API ì‘ë‹µì˜ 'data' ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            raw_models = api_data.get('data', [])
            
            # 1. ì§€ëŠ¥ ì§€ìˆ˜(Intelligence Index) ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            raw_models.sort(
                key=lambda x: x.get('evaluations', {}).get('artificial_analysis_intelligence_index') or 0, 
                reverse=True
            )
            
            models = []
            for index, item in enumerate(raw_models[:15]): # ìƒìœ„ 15ê°œ ëª¨ë¸ ì¶”ì¶œ
                evals = item.get('evaluations', {})
                pricing = item.get('pricing', {})
                creator = item.get('model_creator', {})
                
                # ê°€ê²© ë“±ê¸‰ ê³„ì‚° (100ë§Œ í† í°ë‹¹ ê°€ê²© ê¸°ì¤€)
                price_val = pricing.get('price_1m_blended_3_to_1') or 0
                if price_val == 0: price_str = "Free"
                elif price_val < 0.5: price_str = "$"
                elif price_val < 2.0: price_str = "$$"
                elif price_val < 10.0: price_str = "$$$"
                else: price_str = "$$$$"

                # ë°ì´í„° ë§¤í•‘
                models.append({
                    "rank": index + 1,
                    "name": item.get('name'),
                    "company": creator.get('name', 'Unknown'),
                    "score": evals.get('artificial_analysis_intelligence_index') or 0,
                    "price": price_str,
                    "usage": 98 - (index * 2), # ìˆœìœ„ì— ë”°ë¥¸ ê°€ìƒ ì‚¬ìš©ë¥ 
                    "color": "#00fff2" if index < 3 else "#a78bfa",
                    "url": f"https://artificialanalysis.ai/models/{item.get('slug')}",
                    "isKorean": creator.get('name') in ["Naver", "Wrtn", "Upstage", "Kakao"],
                    "newFeatures": ["API Live"] if index < 5 else []
                })
            
            print(f"âœ… ì‹¤ì œ ëª¨ë¸ {len(models)}ê°œ ë§¤í•‘ ì™„ë£Œ!")
            return models
        else:
            print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        return []

# --- ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ (scrape_lmsys_arena, scrape_voice_models ë“±)ì€ ë™ì¼í•˜ê²Œ ìœ ì§€ ---

def scrape_lmsys_arena():
    return [{"rank": 1, "name": "Nano Banana Pro", "company": "Google", "score": 95, "price": "$$", "usage": 92, "specialty": "Photorealism", "color": "#f472b6", "url": "https://labs.google/nano", "isKorean": False}]

def scrape_voice_models():
    return [
        {"rank": 1, "name": "ElevenLabs Turbo v3", "company": "ElevenLabs", "score": 96, "price": "$$", "usage": 94, "specialty": "ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘", "color": "#a78bfa", "url": "https://elevenlabs.io", "isKorean": False},
        {"rank": 3, "name": "Clova Dubbing", "company": "Naver", "score": 91, "price": "$$", "usage": 78, "specialty": "í•œêµ­ì–´ íŠ¹í™”", "color": "#10b981", "url": "https://clovadubbing.naver.com", "isKorean": True}
    ]

def scrape_agent_services():
    return [{"rank": 1, "name": "Genspark", "company": "Genspark", "score": 93, "price": "Free", "usage": 89, "specialty": "AI ê²€ìƒ‰ ì—”ì§„", "color": "#a78bfa", "url": "https://genspark.ai", "isKorean": False}]

def scrape_stanford_hai():
    return [{"rank": 6, "name": "í•œêµ­", "flag": "ğŸ‡°ğŸ‡·", "aiPower": 5700, "investment": 11.8, "adoption": 42.1, "models": 78, "trend": "up"}]

def generate_insights():
    return [{"title": "í•œêµ­ AI ì„œë¹„ìŠ¤ ì•½ì§„", "description": "êµ­ë‚´ ì„œë¹„ìŠ¤ë“¤ì´ ê¸€ë¡œë²Œ í†±10 ì§„ì… ì¤‘.", "icon": "ğŸ‡°ğŸ‡·", "color": "border-blue-400"}]

def main():
    print("ğŸš€ AI Model Observatory ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘\n")
    
    data = {
        "llmModels": scrape_artificialanalysis(),
        "imageModels": scrape_lmsys_arena(),
        "videoModels": [{"rank": 1, "name": "Veo 3.1", "company": "Google", "score": 94, "price": "$$$", "usage": 88, "duration": "8s", "color": "#f472b6", "url": "https://deepmind.google/veo/", "isKorean": False}],
        "voiceModels": scrape_voice_models(),
        "agentModels": scrape_agent_services(),
        "countries": scrape_stanford_hai(),
        "insights": generate_insights(),
        "lastUpdate": datetime.now().isoformat(),
        "metadata": {"version": "1.0", "source": "Automated API"}
    }
    
    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print("\nâœ… data.json íŒŒì¼ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main()
