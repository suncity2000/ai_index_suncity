#!/usr/bin/env python3
import json
import requests
import os
from datetime import datetime

def scrape_artificialanalysis():
    print("ðŸ“Š Artificial Analysis APIì—ì„œ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    # 1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ í‚¤ ê°€ì ¸ì˜¤ê¸° (GitHub Secrets)
    api_key = os.environ.get('AI_MODELS_KEY')
    
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© (í…ŒìŠ¤íŠ¸ í›„ ë°˜ë“œì‹œ ì§€ìš°ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬í•˜ì„¸ìš”)
    # api_key = "ì—¬ê¸°ì—_ì‹¤ì œ_í‚¤_ìž…ë ¥" 

    if not api_key:
        print("âŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return []

    url = "https://artificialanalysis.ai/api/v2/data/llms/models" 
    headers = {
        "x-api-key": api_key,
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        print(response.json()) # ì´ ì¤„ì´ í•µì‹¬ìž…ë‹ˆë‹¤!
        # ìƒíƒœ ì½”ë“œê°€ 200ì¼ ë•Œë§Œ JSON ë¶„ì„ ì‹œë„
        if response.status_code == 200:
            api_data = response.json()
            raw_models = api_data if isinstance(api_data, list) else api_data.get('models', [])
            
            models = []
            for index, item in enumerate(raw_models[:15]):
                models.append({
                    "rank": index + 1,
                    "name": item.get('model_name') or item.get('name', 'Unknown'),
                    "company": item.get('creator_name') or "AI Research",
                    "score": item.get('intelligence_index') or item.get('intelligence_score', 85),
                    "price": "$$$" if (item.get('price_per_1m_tokens', 0) > 10) else "$$",
                    "usage": 90 - index,
                    "color": "#00fff2" if index < 3 else "#a78bfa",
                    "url": f"https://artificialanalysis.ai/models/{item.get('model_slug') or item.get('slug', '')}",
                    "isKorean": False,
                    "newFeatures": ["Verified API"]
                })
            print(f"âœ… ì‹¤ì œ ëª¨ë¸ {len(models)}ê°œ ìˆ˜ì§‘ ì„±ê³µ!")
            return models
        else:
            print(f"âŒ API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
            return []

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return []

# --- ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ (scrape_lmsys_arena, scrape_voice_models ë“±)ì€ ë™ì¼í•˜ê²Œ ìœ ì§€ ---

def scrape_lmsys_arena():
    return [{"rank": 1, "name": "Nano Banana Pro", "company": "Google", "score": 95, "price": "$$", "usage": 92, "specialty": "Photorealism", "color": "#f472b6", "url": "https://labs.google/nano", "isKorean": False}]

def scrape_voice_models():
    return [
        {"rank": 1, "name": "ElevenLabs Turbo v3", "company": "ElevenLabs", "score": 96, "price": "$$", "usage": 94, "specialty": "ìžì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘", "color": "#a78bfa", "url": "https://elevenlabs.io", "isKorean": False},
        {"rank": 3, "name": "Clova Dubbing", "company": "Naver", "score": 91, "price": "$$", "usage": 78, "specialty": "í•œêµ­ì–´ íŠ¹í™”", "color": "#10b981", "url": "https://clovadubbing.naver.com", "isKorean": True}
    ]

def scrape_agent_services():
    return [{"rank": 1, "name": "Genspark", "company": "Genspark", "score": 93, "price": "Free", "usage": 89, "specialty": "AI ê²€ìƒ‰ ì—”ì§„", "color": "#a78bfa", "url": "https://genspark.ai", "isKorean": False}]

def scrape_stanford_hai():
    return [{"rank": 6, "name": "í•œêµ­", "flag": "ðŸ‡°ðŸ‡·", "aiPower": 5700, "investment": 11.8, "adoption": 42.1, "models": 78, "trend": "up"}]

def generate_insights():
    return [{"title": "í•œêµ­ AI ì„œë¹„ìŠ¤ ì•½ì§„", "description": "êµ­ë‚´ ì„œë¹„ìŠ¤ë“¤ì´ ê¸€ë¡œë²Œ í†±10 ì§„ìž… ì¤‘.", "icon": "ðŸ‡°ðŸ‡·", "color": "border-blue-400"}]

def main():
    print("ðŸš€ AI Model Observatory ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘\n")
    
    data = {
        "llmModels": scrape_artificialanalysis(),
        "imageModels": scrape_lmsys_arena(),
        "videoModels": [{"rank": 1, "name": "Veo 3.1", "company": "Google", "score": 94, "price": "$$$", "usage": 88, "duration": "8s", "color": "#f472b6", "url": "https://deepmind.google/veo/", "isKorean": False}],
        "voiceModels": scrape_voice_models(),
        "agentModels": scrape_agent_services(),
        "countries": scrape_stanford_hai(),
        "insights": generate_insights(),
        "lastUpdate": datetime.now().isoformat(),
        "metadata": {"version": "1.0", "source": "Automated API"}
    }
    
    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print("\nâœ… data.json íŒŒì¼ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main()
